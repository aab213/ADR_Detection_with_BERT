{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Applying LexNorm to Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "Load in various libraries, plus the LexNorm.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from LexNorm import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Example of how to apply the script. Input to the correct_spelling_mistakes must be tokenized, but running normalize first will do that for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['quetiapine', 'makes', 'me', 'sleepy'], ['-TH-', 'have', 'you', 'heard', 'of', 'pregabalin', '?', 'diabetes']]\n"
     ]
    }
   ],
   "source": [
    "#example of usage\n",
    "\n",
    "test = ['Seroquel makes me sleepy', '@TwitterHandle Have you heard of Lyrica? #diabetes']\n",
    "\n",
    "# Normalize with our final version of the normalizer, including transform from drug brand name\n",
    "test2 = Normalizer().drug_normalize(test)\n",
    "print(test2)\n",
    "\n",
    "#correct spelling mistakes - input must be tokenized\n",
    "#test3 = Normalizer().correct_spelling_mistakes(test2)[0]\n",
    "#print(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Applying to tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Load in the train/dev/test tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('./data/train.tsv', sep=\"\\t\", \n",
    "                       names = ['tweet_id','label','tweet'])\n",
    "dev_df = pd.read_csv('./data/dev.tsv', sep=\"\\t\", \n",
    "                       names = ['tweet_id','label','tweet'])\n",
    "test_df = pd.read_csv('./data/test.tsv', sep=\"\\t\", \n",
    "                       names = ['tweet_id','user_id','tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Parse out just the tweet column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "train_tweets = train_df.tweet\n",
    "dev_tweets = dev_df.tweet\n",
    "test_tweets = test_df.tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "To run the full normalizer + spell corrector pipeline, run below. For our models, we just ran the drug_normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run:  101 sec\n",
      "Total tweets processed:  5136\n",
      "Total tweets corrected:  680\n",
      "Total tokens corrected:  789\n",
      "Unique tokens replaced:  646\n"
     ]
    }
   ],
   "source": [
    "# full normalizer (takes care of tokenization) and correct spelling mistakes\n",
    "start = timer()\n",
    "normalized_tweets = Normalizer().normalize(dev_tweets)\n",
    "corrected_tweets = Normalizer().correct_spelling_mistakes(normalized_tweets)\n",
    "end = timer()\n",
    "print(\"Time to run: \", int(end-start), \"sec\")\n",
    "print(\"Total tweets processed: \", len(corrected_tweets[1]))\n",
    "print(\"Total tweets corrected: \", np.count_nonzero(corrected_tweets[1]))\n",
    "print(\"Total tokens corrected: \", sum(corrected_tweets[1]))\n",
    "print(\"Unique tokens replaced: \", len(corrected_tweets[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs just the simple normalizer + drug normalizer and is our final preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run:  1 sec\n"
     ]
    }
   ],
   "source": [
    "# normalize (takes care of tokenization) and correct spelling mistakes\n",
    "start = timer()\n",
    "normalized_tweets = Normalizer().drug_normalize(dev_tweets)\n",
    "end = timer()\n",
    "print(\"Time to run: \", int(end-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>normalized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@chrisbrown im on depokaote, zoloft, paxil and...</td>\n",
       "      <td>-TH- i am on depokaote , zoloft , paxil and pr...</td>\n",
       "      <td>-th- i am on depokaote , sertraline , paroxeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>rt @ovariancancers: clinical oncology news - d...</td>\n",
       "      <td>rt -TH- : clinical oncology news - duloxetine ...</td>\n",
       "      <td>rt -th- : clinical oncology news - duloxetine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>whoever created fairytales needs to take respo...</td>\n",
       "      <td>whoever created fairytales needs to take respo...</td>\n",
       "      <td>whoever created fairytales needs to take respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>@anorexic0 @ewdustin -generic drugs as effecti...</td>\n",
       "      <td>-TH- -TH- -generic drugs as effective as amgen...</td>\n",
       "      <td>-th- -th- -generic drugs as effective as amgen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>@gussypalore weekly enbrel injections. paracet...</td>\n",
       "      <td>-TH- weekly enbrel injections . paracetamol . ...</td>\n",
       "      <td>-th- weekly etanercept injections . paracetamo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              label  \\\n",
       "0         0  @chrisbrown im on depokaote, zoloft, paxil and...   \n",
       "1         0  rt @ovariancancers: clinical oncology news - d...   \n",
       "2         0  whoever created fairytales needs to take respo...   \n",
       "3         0  @anorexic0 @ewdustin -generic drugs as effecti...   \n",
       "4         0  @gussypalore weekly enbrel injections. paracet...   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  -TH- i am on depokaote , zoloft , paxil and pr...   \n",
       "1  rt -TH- : clinical oncology news - duloxetine ...   \n",
       "2  whoever created fairytales needs to take respo...   \n",
       "3  -TH- -TH- -generic drugs as effective as amgen...   \n",
       "4  -TH- weekly enbrel injections . paracetamol . ...   \n",
       "\n",
       "                                    normalized_tweet  \n",
       "0  -th- i am on depokaote , sertraline , paroxeti...  \n",
       "1  rt -th- : clinical oncology news - duloxetine ...  \n",
       "2  whoever created fairytales needs to take respo...  \n",
       "3  -th- -th- -generic drugs as effective as amgen...  \n",
       "4  -th- weekly etanercept injections . paracetamo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# throw back in a dataframe\n",
    "normalized_dev_tweets = pd.Series([\" \".join(x) for x in normalized_tweets[0]])\n",
    "dev_df['normalized_tweet'] = normalized_dev_tweets\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.tsv',sep=\"\\t\",index=False,index_label=False, header=False)\n",
    "dev_df.to_csv('dev.tsv',sep=\"\\t\",index=False,index_label=False, header=False)\n",
    "test_df.to_csv('test.tsv',sep=\"\\t\",index=False,index_label=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = pd.concat([train_df, dev_df], axis=0)\n",
    "full_train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df.to_csv('full_training.tsv',sep=\"\\t\",index=True,index_label=False, header=False,\n",
    "                     columns=['label','tweet','normalized_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Spelling Correction Analysis\n",
    "\n",
    "Analyze output of spell corrector, if using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words processed:  206916\n",
      "Total tokens corrected:  5379\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words processed: \", sum([len(x) for x in normalized_tweets]))\n",
    "print(\"Total tokens corrected: \", sum(corrected_tweets[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Take a look at some examples of corrections that it made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arthrotec', 'arthritis'),\n",
       " ('followfriday', ['follow', 'friday']),\n",
       " ('tt', 'ass'),\n",
       " ('xanaxdreams', ['xanax', 'dreams']),\n",
       " ('toastie', 'chocolate'),\n",
       " ('spondyloarthritis', 'arthritis'),\n",
       " ('surgeryblue', ['surgery', 'blue']),\n",
       " ('dysthymia', 'schizophrenia'),\n",
       " ('aderol', 'adderall'),\n",
       " ('injectable', 'injection'),\n",
       " ('bussing', 'missing'),\n",
       " ('undersleep', 'understand'),\n",
       " ('doxycycline', 'ciprofloxacin'),\n",
       " ('sai', 'said'),\n",
       " ('macrobid', 'ciprofloxacin'),\n",
       " ('crazytown', ['crazy', 'town']),\n",
       " ('chd', 'ischemic'),\n",
       " ('hbp', 'metoprolol'),\n",
       " ('sleepdisorders', ['sleep', 'disorders']),\n",
       " ('infront', 'instead')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample( corrected_tweets[4].items(), 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
